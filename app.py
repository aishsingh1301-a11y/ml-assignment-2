# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1S8IiBeTLqE0g3tMZ3x1zK_AXaFc_Z9jM
"""

pip install streamlit

import streamlit as st
import pandas as pd
import joblib
import numpy as np
from sklearn.metrics import (
    accuracy_score, roc_auc_score, precision_score,
    recall_score, f1_score, matthews_corrcoef,
    confusion_matrix, classification_report
)
import seaborn as sns
import matplotlib.pyplot as plt

# Title and description
st.title("Breast Cancer Tumor Classification – Model Demo")
st.markdown("""
This app demonstrates 6 trained classification models on the Breast Cancer Wisconsin dataset.
Upload a **test CSV** with **30 feature columns** + **'target'** column to see predictions and metrics.
""")

# Dictionary of models (filename without .pkl)
models_dict = {
    "Logistic Regression": "logistic_regression",
    "Decision Tree": "decision_tree",
    "kNN": "knn",
    "Naive Bayes": "naive_bayes",
    "Random Forest": "random_forest",
    "XGBoost": "xgboost"
}

# Load scaler once (used for all models)
try:
    scaler = joblib.load('model/scaler.pkl')
except Exception as e:
    st.error(f"Error loading scaler: {e}")
    st.stop()

# File uploader – required by assignment
uploaded_file = st.file_uploader(
    "Upload your test CSV file (must have 30 features + 'target' column)",
    type="csv"
)

if uploaded_file is not None:
    try:
        test_df = pd.read_csv(uploaded_file)

        # Basic validation
        expected_features = [
            'mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness',
            'mean compactness', 'mean concavity', 'mean concave points', 'mean symmetry',
            'mean fractal dimension', 'radius error', 'texture error', 'perimeter error',
            'area error', 'smoothness error', 'compactness error', 'concavity error',
            'concave points error', 'symmetry error', 'fractal dimension error',
            'worst radius', 'worst texture', 'worst perimeter', 'worst area',
            'worst smoothness', 'worst compactness', 'worst concavity',
            'worst concave points', 'worst symmetry', 'worst fractal dimension'
        ]

        missing_cols = [col for col in expected_features if col not in test_df.columns]
        if missing_cols:
            st.error(f"Missing feature columns: {missing_cols}")
            st.stop()
        if 'target' not in test_df.columns:
            st.error("CSV must contain a 'target' column (0 = malignant, 1 = benign) for evaluation.")
            st.stop()

        # Show preview
        st.subheader("Uploaded Data Preview")
        st.dataframe(test_df.head())

        # Prepare data
        X_test = test_df[expected_features]
        y_test = test_df['target']

        # Scale features (same as training)
        X_test_scaled = scaler.transform(X_test)

        # Model selection dropdown – required
        selected_model_name = st.selectbox("Select a Model to Evaluate", list(models_dict.keys()))

        if selected_model_name:
            model_filename = models_dict[selected_model_name]
            model_path = f"model/{model_filename}.pkl"

            try:
                model = joblib.load(model_path)
                st.success(f"Loaded {selected_model_name} successfully.")
            except Exception as e:
                st.error(f"Could not load model {model_filename}: {e}")
                st.stop()

            # Predict
            y_pred = model.predict(X_test_scaled)
            y_prob = model.predict_proba(X_test_scaled)[:, 1] if hasattr(model, "predict_proba") else None

            # Metrics
            acc = accuracy_score(y_test, y_pred)
            auc = roc_auc_score(y_test, y_prob) if y_prob is not None else "N/A (model without probabilities)"
            prec = precision_score(y_test, y_pred)
            rec = recall_score(y_test, y_pred)
            f1 = f1_score(y_test, y_pred)
            mcc = matthews_corrcoef(y_test, y_pred)

            st.subheader("Evaluation Metrics")
            cols = st.columns(3)
            cols[0].metric("Accuracy", f"{acc:.4f}")
            cols[1].metric("AUC", f"{auc:.4f}" if isinstance(auc, float) else auc)
            cols[2].metric("MCC", f"{mcc:.4f}")

            cols = st.columns(3)
            cols[0].metric("Precision", f"{prec:.4f}")
            cols[1].metric("Recall", f"{rec:.4f}")
            cols[2].metric("F1 Score", f"{f1:.4f}")

            # Confusion Matrix
            st.subheader("Confusion Matrix")
            cm = confusion_matrix(y_test, y_pred)
            fig, ax = plt.subplots(figsize=(5, 4))
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
                        xticklabels=['Malignant', 'Benign'], yticklabels=['Malignant', 'Benign'])
            ax.set_xlabel("Predicted")
            ax.set_ylabel("Actual")
            st.pyplot(fig)

            # Classification Report
            st.subheader("Classification Report")
            st.text(classification_report(y_test, y_pred, target_names=['Malignant', 'Benign']))

    except Exception as e:
        st.error(f"Error processing file: {e}")
else:
    st.info("Please upload a test CSV to start evaluation.")

