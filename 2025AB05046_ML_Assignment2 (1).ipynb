{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OTn7tgrJr-r",
        "outputId": "13d2b4a8-9142-4c7c-85bc-543d8338376e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logistic_regression trained and saved.\n",
            "decision_tree trained and saved.\n",
            "knn trained and saved.\n",
            "naive_bayes trained and saved.\n",
            "random_forest trained and saved.\n",
            "xgboost trained and saved.\n",
            "\n",
            "=== Model Comparison Table ===\n",
            "                     Accuracy     AUC  Precision  Recall      F1     MCC\n",
            "logistic_regression    0.9825  0.9954     0.9861  0.9861  0.9861  0.9623\n",
            "decision_tree          0.9123  0.9157     0.9559  0.9028  0.9286  0.8174\n",
            "knn                    0.9649  0.9792     0.9595  0.9861  0.9726  0.9245\n",
            "naive_bayes            0.9298  0.9868     0.9444  0.9444  0.9444  0.8492\n",
            "random_forest          0.9561  0.9937     0.9589  0.9722  0.9655  0.9054\n",
            "xgboost                0.9561  0.9901     0.9467  0.9861  0.9660  0.9058\n",
            "\n",
            "=== Observations ===\n",
            "Logistic regression: Very strong linear model. High AUC and balanced precision/recall due to well-separated classes.\n",
            "Decision tree: Prone to slight overfitting. Good recall but lower precision than ensembles.\n",
            "Knn: Distance-based; performs well after scaling. Competitive but sensitive to k.\n",
            "Naive bayes: Fast and surprisingly effective despite independence assumption. High recall.\n",
            "Random forest: Ensemble power → excellent AUC, robust, reduces variance over single tree.\n",
            "Xgboost: Best overall performance. Highest AUC/MCC thanks to boosting and handling of feature interactions.\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "# Create model folder\n",
        "os.makedirs('model', exist_ok=True)\n",
        "\n",
        "# Load dataset directly (no file needed)\n",
        "cancer = load_breast_cancer(as_frame=True)\n",
        "df = cancer.frame\n",
        "\n",
        "# Features and target (target: 0 = malignant, 1 = benign)\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Scale all features (all are numeric)\n",
        "scaler = StandardScaler()\n",
        "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
        "\n",
        "# Save scaler for Streamlit app\n",
        "joblib.dump(scaler, 'model/scaler.pkl')\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Dictionary to store results\n",
        "results = {}\n",
        "\n",
        "def train_evaluate_save(model, name):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    auc = roc_auc_score(y_test, y_prob) if y_prob is not None else np.nan\n",
        "    prec = precision_score(y_test, y_pred)\n",
        "    rec = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "    results[name] = {\n",
        "        'Accuracy': round(acc, 4),\n",
        "        'AUC': round(auc, 4),\n",
        "        'Precision': round(prec, 4),\n",
        "        'Recall': round(rec, 4),\n",
        "        'F1': round(f1, 4),\n",
        "        'MCC': round(mcc, 4)\n",
        "    }\n",
        "\n",
        "    joblib.dump(model, f'model/{name}.pkl')\n",
        "    print(f\"{name} trained and saved.\")\n",
        "\n",
        "# 1. Logistic Regression\n",
        "train_evaluate_save(LogisticRegression(max_iter=1000), 'logistic_regression')\n",
        "\n",
        "# 2. Decision Tree\n",
        "train_evaluate_save(DecisionTreeClassifier(random_state=42), 'decision_tree')\n",
        "\n",
        "# 3. KNN\n",
        "train_evaluate_save(KNeighborsClassifier(), 'knn')\n",
        "\n",
        "# 4. Naive Bayes (Gaussian - suitable for continuous features)\n",
        "train_evaluate_save(GaussianNB(), 'naive_bayes')\n",
        "\n",
        "# 5. Random Forest\n",
        "train_evaluate_save(RandomForestClassifier(random_state=42), 'random_forest')\n",
        "\n",
        "# 6. XGBoost\n",
        "train_evaluate_save(XGBClassifier(eval_metric='logloss', random_state=42), 'xgboost')\n",
        "\n",
        "# Show comparison table\n",
        "metrics_df = pd.DataFrame(results).T\n",
        "print(\"\\n=== Model Comparison Table ===\")\n",
        "print(metrics_df)\n",
        "\n",
        "# Observations (update these slightly based on your actual run if needed)\n",
        "observations = {\n",
        "    'logistic_regression': \"Very strong linear model. High AUC and balanced precision/recall due to well-separated classes.\",\n",
        "    'decision_tree': \"Prone to slight overfitting. Good recall but lower precision than ensembles.\",\n",
        "    'knn': \"Distance-based; performs well after scaling. Competitive but sensitive to k.\",\n",
        "    'naive_bayes': \"Fast and surprisingly effective despite independence assumption. High recall.\",\n",
        "    'random_forest': \"Ensemble power → excellent AUC, robust, reduces variance over single tree.\",\n",
        "    'xgboost': \"Best overall performance. Highest AUC/MCC thanks to boosting and handling of feature interactions.\"\n",
        "}\n",
        "\n",
        "print(\"\\n=== Observations ===\")\n",
        "for model, obs in observations.items():\n",
        "    print(f\"{model.capitalize().replace('_', ' ')}: {obs}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After: cancer = load_breast_cancer(as_frame=True)\n",
        "df = cancer.frame\n",
        "\n",
        "# Save a small test set (e.g., 100 rows)\n",
        "test_sample = df.sample(n=100, random_state=42)  # or df.iloc[-100:]\n",
        "test_sample.to_csv(\"breast_cancer_test_sample.csv\", index=False)\n",
        "\n",
        "print(\"Test CSV created: breast_cancer_test_sample.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9WH84ZUJtvl",
        "outputId": "95faa872-cce8-4492-8285-5cbcdefe3db1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test CSV created: breast_cancer_test_sample.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cXV_bfOsXY98"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}